http-server:
  addr: ":7091"

health:
  path: "/api/health"

# storages
kafka:
  servers: "${BOOTSTRAP_SERVERS:localhost:9092}"
  producer:
    options:
      go.produce.channel.size: ${KAFKA_PRODUCE_SIZE:200000}

kafka.topic.initializer:
  force: ${KAFKA_INIT_FORCE_SUCCESS:true}
  topics:
    - spot-container-log
    - spot-job-log
    - spot-metrics
    - spot-events
    - spot-analytics
    - spot-trace
    - spot-alert-record
    - spot-notify-record
    - spot-entity
    - msp-tracing-metrics
    - msp-jaeger-trace
    - erda-spans
    - erda-trace-metrics

redis:
  addr: "${REDIS_ADDR}"
  password: "${REDIS_PASSWORD}"
  db: ${REDIS_DB:0}
  master_name: "${REDIS_MASTER_NAME}"
  sentinels_addr: "${REDIS_SENTINELS_ADDR}"

mysql:
  host: "${MYSQL_HOST:localhost}"
  port: ${MYSQL_PORT:3306}
  username: "${MYSQL_USERNAME:root}"
  password: "${MYSQL_PASSWORD:123456}"
  database: "${MYSQL_DATABASE:dice}"

etcd:
  endpoints: "${ETCD_ENDPOINTS:http://localhost:2379}"
  tls:
    cert_file: "${ETCD_CERT_FILE:/certs/etcd-client.pem}"
    cert_key_file: "${ETCD_CERT_KEY_FILE:/certs/etcd-client-key.pem}"
    ca_file: "${ETCD_CA_FILE:/certs/etcd-ca.pem}"

etcd-election@index:
  root_path: "/erda/monitor-index-rollover-election"

etcd-election@table-loader:
  root_path: "/erda/monitor-ck-table-loader-election"

etcd-election@table-initializer:
  root_path: "/erda/monitor-ck-table-initializer-election"

etcd-mutex:
  root_path: "/erda/streaming"

clickhouse:
  _enable: ${CLICKHOUSE_ENABLE:false}
  addr: "${CLICKHOUSE_ADDR:localhost:9000}"
  username: "${CLICKHOUSE_USERNAME:default}"
  password: "${CLICKHOUSE_PASSWORD:default}"
  conn_open_strategy: "round_robin"

clickhouse.table.initializer@log:
  _enable: ${CLICKHOUSE_ENABLE:false}
  table_prefix: "logs"
  ttl_sync_interval: "${CLICKHOUSE_TABLE_TTL_SYNC_INTERVAL:24h}"
  default_ddl_files:
    - path: "conf/clickhouse/logs_ddl_create_db.sql"
      ignore_err: "false"
    - path: "conf/clickhouse/logs_ddl_create_default_tables.sql"
      ignore_err: "false"
  tenant_ddl_files:
    - path: "conf/clickhouse/logs_ddl_create_tenant_tables.sql"
      ignore_err: "true"

clickhouse.table.creator@log:
  _enable: ${WRITE_LOG_TO_CLICKHOUSE_ENABLE:false}
  ddl_template: "${conf}/clickhouse/logs_ddl_create_tenant_tables.sql"
  default_write_table: "logs"
  table_prefix: "logs"

clickhouse.table.loader@log:
  _enable: ${WRITE_LOG_TO_CLICKHOUSE_ENABLE:false}
  table_prefix: "logs"
  default_search_table: "logs_all"

log-storage-clickhouse:
  _enable: ${WRITE_LOG_TO_CLICKHOUSE_ENABLE:false}

# elasticsearch for log
elasticsearch@log:
  _enable: ${LOG_ELASTICSEARCH_ENABLE:false}
  urls: "${LOG_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${LOG_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${LOG_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${LOG_ELASTICSEARCH_SECURITY_PASSWORD}"

elasticsearch.index.initializer@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  templates:
    - name: "erda-logs"
      path: "${conf}/log_index_template.json"

elasticsearch.index.loader@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "erda-logs-"
      patterns:
        - "<org>-{number}"
        - "<org>.<key>-{number}"

elasticsearch.index.creator@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  patterns:
    - first_index: "erda-logs-<org>-000001"
      alias: "erda-logs-<org>-rollover"
    - first_index: "erda-logs-<org>.<key>-000001"
      alias: "erda-logs-<org>.<key>-rollover"
  remove_conflicting_indices: true

elasticsearch.index.rollover@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  check_interval: "30s"
  body_file: "${conf}/index_rollover.json"
  patterns:
    - index: "erda-logs-<org>-{number}"
      alias: "erda-logs-<org>-rollover"
    - index: "erda-logs-<org>.<key>-{number}"
      alias: "erda-logs-<org>.<key>-rollover"

storage-retention-strategy@log:
  load_from_database: true
  ttl_reload_interval: "3m"
  default_ttl: "${LOG_TTL:168h}"

log-storage-elasticsearch:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  write_timeout: "1m"
  index_type: "logs"

log-persist:
  _enable: ${WRITE_LOG_TO_ES_ENABLE|WRITE_LOG_TO_CLICKHOUSE_ENABLE:true}
  input:
    topics: "${LOG_TOPICS:spot-container-log,spot-job-log}"
    group: "${LOG_GROUP_ID:erda-logs-dev}"
    options:
      auto.offset.reset: "${LOG_PERSIST_INPUT_KAFKA_AUTO_OFFSET_RESET:earliest}"
      queued.max.messages.kbytes: ${LOG_PERSIST_INPUT_KAFKA_QUEUE_SIZE_KB:102400}
  id_keys: "${LOG_ID_KEYS:TERMINUS_DEFINE_TAG,terminus_define_tag,MESOS_TASK_ID,mesos_task_id}"
  read_timeout: "5s"
  buffer_size: ${LOG_BATCH_SIZE:200}
  parallelism: ${LOG_PERSIST_PARALLELISM:3}
  storage_writer_service: "${LOG_STORAGE_WRITER_SERVICE:log-storage-elasticsearch-writer}"
  print_invalid_log: false

cassandra:
  _enable: ${CASSANDRA_ENABLE:false}
  host: "${CASSANDRA_ADDR:localhost:9042}"
  security: ${CASSANDRA_SECURITY_ENABLE:false}
  username: ${CASSANDRA_SECURITY_USERNAME}
  password: ${CASSANDRA_SECURITY_PASSWORD}
  timeout: "${CASSANDRA_TIMEOUT:3s}"

log-persist-v1:
  _enable: ${WRITE_LOG_TO_CASSANDRA_ENABLE:false}
  input:
    topics: "${LOG_TOPICS:spot-container-log,spot-job-log}"
    group: "${LOG_GROUP_ID:spot-monitor-log-dev}"
    parallelism: ${LOG_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:earliest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
      queued.max.messages.kbytes: ${LOGS_STORE_INPUT_CONSUMER_QUEUE_SIZE_KB:102400} # 300MB = 100MB * parallelism
  output:
    id_keys: "${LOG_ID_KEYS:TERMINUS_DEFINE_TAG,terminus_define_tag,MESOS_TASK_ID,mesos_task_id}"
    log_schema:
      org_refresh_interval: "${LOG_SCHEMA_ORG_REFRESH_INTERVAL:3m}"
    cassandra:
      writer_config:
        parallelism: ${CASSANDRA_PARALLELISM:3}
        batch:
          size_bytse: ${CASSANDRA_BATCH_SIZE_BYTES:307200}
          size: ${CASSANDRA_BATCH_SIZE:50}
          timeout: ${CASSANDRA_BATCH_TIMEOUT:10s}
        retry: ${CASSANDRA_WRITE_RETRY:-1}  # -1 means block forever. kafka will handle the issue of stream block
      session_config:
        keyspace:
          name: "spot_prod"
          auto: ${LOG_STORE_CASSANDRA_SESSION_KEYSPACE_AUTO:true} # 自动创建 keyspace
          replication:
            class: ${CASSANDRA_KEYSPACE_REPLICATION_CLASS:SimpleStrategy}
            factor: ${CASSANDRA_KEYSPACE_REPLICATION_FACTOR:2}
        reconnection:
          check_interval: ${LOG_STORE_CASSANDRA_RECONNECTION_CHECK_INTERVAL:3m}
      gc_grace_seconds: 86400

# elasticsearch for event
elasticsearch@event:
  _enable: ${EVENT_ELASTICSEARCH_ENABLE:false}
  urls: "${EVENT_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${EVENT_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${EVENT_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${EVENT_ELASTICSEARCH_SECURITY_PASSWORD}"

elasticsearch.index.initializer@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  templates:
    - name: "erda-events"
      path: "${conf}/event_index_template.json"

elasticsearch.index.loader@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "erda-events-"
      patterns:
        - "<event>-<namespace>-{number}"
        - "<event>-<namespace>.<key>-{number}"

elasticsearch.index.creator@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  patterns:
    - first_index: "erda-events-<event>-<namespace>-000001"
      alias: "erda-events-<event>-<namespace>-rollover"
    - first_index: "erda-events-<event>-<namespace>.<key>-000001"
      alias: "erda-events-<event>-<namespace>.<key>-rollover"
  remove_conflicting_indices: true

elasticsearch.index.rollover@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  check_interval: "30s"
  body_file: "${conf}/index_rollover.json"
  patterns:
    - index: "erda-events-<event>-<namespace>-{number}"
      alias: "erda-events-<event>-<namespace>-rollover"
    - index: "erda-events-<event>-<namespace>.<key>-{number}"
      alias: "erda-events-<event>-<namespace>.<key>-rollover"

storage-retention-strategy@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  load_from_database: false
  ttl_reload_interval: "3m"

event-storage-elasticsearch:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  write_timeout: "1m"
  index_type: "events"

event-persist:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  input:
    topics: "${EVENT_TOPICS:spot-events}"
    group: "${EVENT_GROUP_ID:spot-monitor-event-dev}"
  read_timeout: "5s"
  buffer_size: ${EVENT_BATCH_SIZE:200}
  parallelism: ${EVENT_PERSIST_PARALLELISM:3}
  print_invalid_event: false

# elasticsearch for metric
elasticsearch:
  urls: "${ES_URL:http://localhost:9200}"
  security: ${ES_SECURITY_ENABLE:false}
  username: "${ES_SECURITY_USERNAME}"
  password: "${ES_SECURITY_PASSWORD}"

elasticsearch.index.initializer@metric:
  templates:
    - name: "spot_metric_template"
      path: "${conf}/metric_index_template.json"

elasticsearch.index.loader@metric:
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "spot-"
      patterns:
        - "empty"
        - "<metric>-<namespace>.<key>-r-{number}"
        - "<metric>-<namespace>-r-{number}"
        - "<metric>-<namespace>-m-{}"
        - "<metric>-<namespace>-m-{}"
        - "<metric>-<namespace>.<key>-<timestamp>"
        - "<metric>-<namespace>-<timestamp>"
        - "<metric>-<namespace>.<key>"
        - "<metric>-<namespace>"

elasticsearch.index.creator@metric:
  patterns:
    - first_index: "spot-<metric>-<namespace>-r-000001"
      alias: "spot-<metric>-<namespace>-rollover"
    - first_index: "spot-<metric>-<namespace>.<key>-r-000001"
      alias: "spot-<metric>-<namespace>.<key>-rollover"
  fixed_patterns:
    - "spot-<metric>-<namespace>"
    - "spot-<metric>-<namespace>.<key>"
  remove_conflicting_indices: true

elasticsearch.index.rollover@metric:
  check_interval: "30m"
  body_file: "${conf}/index_rollover.json"
  patterns:
    - index: "spot-<metric>-<namespace>-r-{number}"
      alias: "spot-<metric>-<namespace>-rollover"
    - index: "spot-<metric>-<namespace>.<key>-r-{number}"
      alias: "spot-<metric>-<namespace>.<key>-rollover"

storage-retention-strategy@metric:
  load_from_database: true
  ttl_reload_interval: "3m"

metric-storage-elasticsearch:
  read_timeout: "1m"
  write_timeout: "1m"
  index_type: "spot"
  dummy_index: "spot-empty"

metric-persist:
  input:
    topics: "${METRIC_TOPICS:spot-metrics,erda-trace-metrics}"
    group: "${METRIC_GROUP_ID:spot-monitor-metrics-dev}"
  read_timeout: "5s"
  buffer_size: ${METRIC_BATCH_SIZE:200}
  parallelism: ${MERTIC_PERSIST_PARALLELISM:3}
  features:
    generate_meta: true
    machine_summary: true

# elasticsearch for span
elasticsearch@span:
  _enable: ${SPAN_ELASTICSEARCH_ENABLE:false}
  urls: "${SPAN_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${SPAN_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${SPAN_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${SPAN_ELASTICSEARCH_SECURITY_PASSWORD}"

elasticsearch.index.initializer@span:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  templates:
    - name: "erda-spans"
      path: "${conf}/span_index_template.json"

elasticsearch.index.loader@span:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "erda-spans-"
      patterns:
        - "<org>-{number}"
        - "<org>.<key>-{number}"

elasticsearch.index.creator@span:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  patterns:
    - first_index: "erda-spans-<org>-000001"
      alias: "erda-spans-<org>-rollover"
    - first_index: "erda-spans-<org>.<key>-000001"
      alias: "erda-spans-<org>.<key>-rollover"
  remove_conflicting_indices: true

elasticsearch.index.rollover@span:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  check_interval: "30s"
  body_file: "${conf}/index_rollover.json"
  patterns:
    - index: "erda-spans-<org>-{number}"
      alias: "erda-spans-<org>-rollover"
    - index: "erda-spans-<org>.<key>-{number}"
      alias: "erda-spans-<org>.<key>-rollover"

storage-retention-strategy@span:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  load_from_database: true
  ttl_reload_interval: "3m"
  default_ttl: "${LOG_TTL:168h}"

span-storage-elasticsearch:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  write_timeout: "1m"
  index_type: "spans"

span-persist:
  _enable: ${WRITE_SPAN_TO_ES_ENABLE:true}
  spot_input:
    topics: "${SPOT_TRACE_TOPICS:spot-trace}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${SPOT_SPOTSPAN_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  oap_input:
    topics: "${OAP_TRACE_TOPICS:msp-jaeger-trace,erda-spans}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${SPOT_OAPSPAN_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  id_keys: "${SPAN_ID_KEYS:TERMINUS_DEFINE_TAG,terminus_define_tag,MESOS_TASK_ID,mesos_task_id}"
  read_timeout: "5s"
  buffer_size: ${SPAN_BATCH_SIZE:200}
  parallelism: ${SPAN_PERSIST_PARALLELISM:3}
  print_invalid_span: false

browser-analytics:
  _enable: ${BROWSER_ENABLE:true}
  input:
    topics: "${BROWSER_TOPICS:spot-analytics}"
    group: "${BROWSER_GROUP_ID:spot-monitor-browser-dev}"
    parallelism: ${BROWSER_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  output:
    topic: "${METRIC_TOPICS:spot-metrics}"
    parallelism: ${KAFKA_PARALLELISM:3}
    batch:
      size:  ${KAFKA_BATCH_SIZE:50}
      timeout: "10s"
  ipdb: "${conf}/ipdata.dat"

trace-storage:
  _enable: ${WRITE_SPAN_TO_CASSANDRA_ENABLE:false}
  spot_input:
    topics: "${SPOT_TRACE_TOPICS:spot-trace}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${SPOT_TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  oap_input:
    topics: "${OAP_TRACE_TOPICS:erda-spans,msp-jaeger-trace}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${OAP_TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  output:
    cassandra:
      writer_config:
        parallelism: ${CASSANDRA_PARALLELISM:3}
        batch:
          size: ${CASSANDRA_BATCH_SIZE:50}
          timeout: ${TRACE_STORE_CASSANDRA_BATCH_TIMEOUT:10s}
        retry: 2
      session_config:
        keyspace:
          name: "spot_prod"
          auto: true # 自动创建 keyspace
          replication:
            class: ${CASSANDRA_KEYSPACE_REPLICATION_CLASS:SimpleStrategy}
            factor: ${CASSANDRA_KEYSPACE_REPLICATION_FACTOR:2}
      gc_grace_seconds: 86400
      ttl: ${TRACE_TTL:168h}
    kafka:
      topic: "${SPOT_TRACE_TOPICS:spot-trace}"
      parallelism: ${KAFKA_PARALLELISM:3}
      batch:
        size:  ${KAFKA_BATCH_SIZE:50}
        timeout: "10s"

# entity
elasticsearch@entity:
  _enable: ${ENTITY_ELASTICSEARCH_ENABLE:false}
  urls: "${ENTITY_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${ENTITY_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${ENTITY_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${ENTITY_ELASTICSEARCH_SECURITY_PASSWORD}"
elasticsearch.index.initializer@entity:
  _enable: ${WRITE_ENTITY_TO_ES_ENABLE:true}
  templates:
    - name: "erda-entity"
      path: "${conf}/entity_index_template.json"
entity-storage-elasticsearch:
  write_timeout: "1m"
  query_timeout: "1m"
  index_type: "entity"
  pattern: "erda-entity-<type>"
entity-persist:
  input:
    topics: "${ENTITY_TOPICS:spot-entity}"
    group: "${ENTITY_GROUP_ID:spot-monitor-entity-dev}"
  read_timeout: "5s"
  buffer_size: ${ENTITY_BATCH_SIZE:200}
  parallelism: ${ENTITY_PERSIST_PARALLELISM:3}

alert-event-storage:
  input:
    topics: "${ALERT_EVENT_TOPICS:spot-alert-record}"
    group: "${ALERT_EVENT_GROUP_ID:spot-alert-event-dev}"
    parallelism: ${TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"

alert-storage:
  input:
    topics: "${TRACE_TOPICS:spot-alert-record}"
    group: "${EVENT_GROUP_ID:spot-alert-record-dev}"
    parallelism: ${TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"

notify-storage:
  input:
    topics: "${TRACE_TOPICS:spot-notify-record}"
    group: "${EVENT_GROUP_ID:spot-notify-record-dev}"
    parallelism: ${TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"

i18n@metric:

http-server@admin:
  addr: ":7098"
pprof:
prometheus:
