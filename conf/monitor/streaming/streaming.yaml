http-server:
  addr: ":7091"

health:
  path: "/api/health"

# storages
kafka:
  servers: "${BOOTSTRAP_SERVERS:localhost:9092}"
  producer:
    options:
      go.produce.channel.size: ${KAFKA_PRODUCE_SIZE:200000}

mysql:
  host: "${MYSQL_HOST:localhost}"
  port: ${MYSQL_PORT:3306}
  username: "${MYSQL_USERNAME:root}"
  password: "${MYSQL_PASSWORD:123456}"
  database: "${MYSQL_DATABASE:dice}"

etcd:
  endpoints: "${ETCD_ENDPOINTS:http://localhost:2379}"
  tls:
    cert_file: "${ETCD_CERT_FILE:/certs/etcd-client.pem}"
    cert_key_file: "${ETCD_CERT_KEY_FILE:/certs/etcd-client-key.pem}"
    ca_file: "${ETCD_CA_FILE:/certs/etcd-ca.pem}"

etcd-election@index:
  root_path: "/erda/monitor-index-rollover-election"

# elasticsearch for log
elasticsearch@log:
  _enable: ${LOG_ELASTICSEARCH_ENABLE:false}
  urls: "${LOG_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${LOG_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${LOG_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${LOG_ELASTICSEARCH_SECURITY_PASSWORD}"

elasticsearch.index.initializer@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  templates:
    - name: "erda-logs"
      path: "${CONFIG_PATH}/log_index_template.json"

elasticsearch.index.loader@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "erda-logs-"
      patterns:
        - "<org>-{number}"
        - "<org>.<key>-{number}"

elasticsearch.index.creator@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  patterns:
    - first_index: "erda-logs-<org>-000001"
      alias: "erda-logs-<org>-rollover"
    - first_index: "erda-logs-<org>.<key>-000001"
      alias: "erda-logs-<org>.<key>-rollover"
  remove_conflicting_indices: true

elasticsearch.index.rollover@log:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  check_interval: "30s"
  body_file: "${CONFIG_PATH}/index_rollover.json"
  patterns:
    - index: "erda-logs-<org>-{number}"
      alias: "erda-logs-<org>-rollover"
    - index: "erda-logs-<org>.<key>-{number}"
      alias: "erda-logs-<org>.<key>-rollover"

storage-retention-strategy@log:
  load_from_database: true
  ttl_reload_interval: "3m"
  default_ttl: "${LOG_TTL:168h}"

log-storage-elasticsearch:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  write_timeout: "1m"
  index_type: "logs"

log-persist:
  _enable: ${WRITE_LOG_TO_ES_ENABLE:true}
  input:
    topics: "${LOG_TOPICS:spot-container-log,spot-job-log}"
    group: "${LOG_GROUP_ID:erda-logs-dev}"
  id_keys: "${LOG_ID_KEYS:TERMINUS_DEFINE_TAG,terminus_define_tag,MESOS_TASK_ID,mesos_task_id}"
  read_timeout: "5s"
  buffer_size: ${LOG_BATCH_SIZE:50}
  parallelism: ${LOG_PERSIST_PARALLELISM:3}
  print_invalid_log: false

cassandra:
  _enable: ${CASSANDRA_ENABLE:true}
  host: "${CASSANDRA_ADDR:localhost:9042}"
  security: ${CASSANDRA_SECURITY_ENABLE:false}
  username: ${CASSANDRA_SECURITY_USERNAME}
  password: ${CASSANDRA_SECURITY_PASSWORD}
  timeout: "${CASSANDRA_TIMEOUT:3s}"
etcd-mutex:
  _enable: ${WRITE_LOG_TO_CASSANDRA_ENABLE:false}
  root_path: "/erda/streaming"
log-persist-v1:
  _enable: ${WRITE_LOG_TO_CASSANDRA_ENABLE:false}
  input:
    topics: "${LOG_TOPICS:spot-container-log,spot-job-log}"
    group: "${LOG_GROUP_ID:spot-monitor-log-dev}"
    parallelism: ${LOG_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
      queued.max.messages.kbytes: ${LOGS_STORE_INPUT_CONSUMER_QUEUE_SIZE_KB:102400} # 300MB = 100MB * parallelism
  output:
    id_keys: "${LOG_ID_KEYS:TERMINUS_DEFINE_TAG,terminus_define_tag,MESOS_TASK_ID,mesos_task_id}"
    log_schema:
      org_refresh_interval: "${LOG_SCHEMA_ORG_REFRESH_INTERVAL:3m}"
    cassandra:
      writer_config:
        parallelism: ${CASSANDRA_PARALLELISM:3}
        batch:
          size: ${CASSANDRA_BATCH_SIZE:50}
          timeout: ${CASSANDRA_BATCH_TIMEOUT:10s}
        retry: -1  # block forever. kafka will handle the issue of stream block
      session_config:
        keyspace:
          name: "spot_prod"
          auto: ${LOG_STORE_CASSANDRA_SESSION_KEYSPACE_AUTO:true} # 自动创建 keyspace
          replication:
            class: ${CASSANDRA_KEYSPACE_REPLICATION_CLASS:SimpleStrategy}
            factor: ${CASSANDRA_KEYSPACE_REPLICATION_FACTOR:2}
        reconnection:
          check_interval: ${LOG_STORE_CASSANDRA_RECONNECTION_CHECK_INTERVAL:3m}
      gc_grace_seconds: 86400

# elasticsearch for event
elasticsearch@event:
  _enable: ${EVENT_ELASTICSEARCH_ENABLE:false}
  urls: "${EVENT_ELASTICSEARCH_URL:http://localhost:9200}"
  security: ${EVENT_ELASTICSEARCH_SECURITY_ENABLE:false}
  username: "${EVENT_ELASTICSEARCH_SECURITY_USERNAME}"
  password: "${EVENT_ELASTICSEARCH_SECURITY_PASSWORD}"

elasticsearch.index.initializer@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  templates:
    - name: "erda-events"
      path: "${CONFIG_PATH}/event_index_template.json"

elasticsearch.index.loader@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "erda-events-"
      patterns:
        - "<event>-<namespace>-{number}"
        - "<event>-<namespace>.<key>-{number}"

elasticsearch.index.creator@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  patterns:
    - first_index: "erda-events-<event>-<namespace>-000001"
      alias: "erda-events-<event>-<namespace>-rollover"
    - first_index: "erda-events-<event>-<namespace>.<key>-000001"
      alias: "erda-events-<event>-<namespace>.<key>-rollover"
  remove_conflicting_indices: true

elasticsearch.index.rollover@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  check_interval: "30s"
  body_file: "${CONFIG_PATH}/index_rollover.json"
  patterns:
    - index: "erda-events-<event>-<namespace>-{number}"
      alias: "erda-events-<event>-<namespace>-rollover"
    - index: "erda-events-<event>-<namespace>.<key>-{number}"
      alias: "erda-events-<event>-<namespace>.<key>-rollover"

storage-retention-strategy@event:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  load_from_database: true
  ttl_reload_interval: "3m"

event-storage-elasticsearch:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  write_timeout: "1m"
  index_type: "events"

event-persist:
  _enable: ${WRITE_EVENT_TO_ES_ENABLE:true}
  input:
    topics: "${EVENT_TOPICS:spot-events}"
    group: "${EVENT_GROUP_ID:erda-events-dev}"
  read_timeout: "5s"
  buffer_size: ${EVENT_BATCH_SIZE:50}
  parallelism: ${EVENT_PERSIST_PARALLELISM:3}
  print_invalid_event: false

# elasticsearch for metric
elasticsearch:
  urls: "${ES_URL:http://localhost:9200}"
  security: ${ES_SECURITY_ENABLE:false}
  username: "${ES_SECURITY_USERNAME}"
  password: "${ES_SECURITY_PASSWORD}"

elasticsearch.index.initializer@metric:
  templates:
    - name: "spot_metric_template"
      path: "${CONFIG_PATH}/metric_index_template.json"

elasticsearch.index.loader@metric:
  load_mode: "LoadFromElasticSearchOnly"
  index_reload_interval: "1m"
  match:
    - prefix: "spot-"
      patterns:
        - "empty"
        - "<metric>-<namespace>.<key>-r-{number}"
        - "<metric>-<namespace>-r-{number}"
        - "<metric>-<namespace>-m-{}"
        - "<metric>-<namespace>-m-{}"
        - "<metric>-<namespace>.<key>-<timestamp>"
        - "<metric>-<namespace>-<timestamp>"
        - "<metric>-<namespace>.<key>"
        - "<metric>-<namespace>"

elasticsearch.index.creator@metric:
  patterns:
    - first_index: "spot-<metric>-<namespace>-r-000001"
      alias: "spot-<metric>-<namespace>-rollover"
    - first_index: "spot-<metric>-<namespace>.<key>-r-000001"
      alias: "spot-<metric>-<namespace>.<key>-rollover"
  fixed_patterns:
    - "spot-<metric>-<namespace>"
    - "spot-<metric>-<namespace>.<key>"
  remove_conflicting_indices: true

elasticsearch.index.rollover@metric:
  check_interval: "30m"
  body_file: "${CONFIG_PATH}/index_rollover.json"
  patterns:
    - index: "spot-<metric>-<namespace>-r-{number}"
      alias: "spot-<metric>-<namespace>-rollover"
    - index: "spot-<metric>-<namespace>.<key>-r-{number}"
      alias: "spot-<metric>-<namespace>.<key>-rollover"

storage-retention-strategy@metric:
  load_from_database: true
  ttl_reload_interval: "3m"

metric-storage-elasticsearch:
  read_timeout: "1m"
  write_timeout: "1m"
  index_type: "spot"
  dummy_index: "spot-empty"

metric-persist:
  input:
    topics: "${METRIC_TOPICS:spot-metrics,msp-tracing-metrics}"
    group: "${METRIC_GROUP_ID:spot-monitor-metrics-dev}"
  read_timeout: "5s"
  buffer_size: ${METRIC_BATCH_SIZE:50}
  parallelism: ${MERTIC_PERSIST_PARALLELISM:3}
  features:
    generate_meta: true
    machine_summary: true

browser-analytics:
  _enable: ${BROWSER_ENABLE:true}
  input:
    topics: "${BROWSER_TOPICS:spot-analytics}"
    group: "${BROWSER_GROUP_ID:spot-monitor-browser-dev}"
    parallelism: ${BROWSER_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  output:
    topic: "${METRIC_TOPICS:spot-metrics}"
    parallelism: ${KAFKA_PARALLELISM:3}
    batch:
      size:  ${KAFKA_BATCH_SIZE:50}
      timeout: "10s"
  ipdb: "${CONFIG_PATH}/ipdata.dat"

trace-storage:
  _enable: ${TRACE_ENABLE:true}
  spot_input:
    topics: "${SPOT_TRACE_TOPICS:spot-trace}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${SPOT_TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  oap_input:
    topics: "${OAP_TRACE_TOPICS:msp-jaeger-trace}"
    group: "${TRACE_GROUP_ID:spot-monitor-trace-dev}"
    parallelism: ${OAP_TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"
  output:
    cassandra:
      writer_config:
        parallelism: ${CASSANDRA_PARALLELISM:3}
        batch:
          size: ${CASSANDRA_BATCH_SIZE:50}
          timeout: ${TRACE_STORE_CASSANDRA_BATCH_TIMEOUT:10s}
        retry: 2
      session_config:
        keyspace:
          name: "spot_prod"
          auto: true # 自动创建 keyspace
          replication:
            class: ${CASSANDRA_KEYSPACE_REPLICATION_CLASS:SimpleStrategy}
            factor: ${CASSANDRA_KEYSPACE_REPLICATION_FACTOR:2}
      gc_grace_seconds: 86400
      ttl: ${TRACE_TTL:168h}
    kafka:
      topic: "${SPOT_TRACE_TOPICS:spot-trace}"
      parallelism: ${KAFKA_PARALLELISM:3}
      batch:
        size:  ${KAFKA_BATCH_SIZE:50}
        timeout: "10s"

alert-storage:
  input:
    topics: "${TRACE_TOPICS:spot-alert-record}"
    group: "${TRACE_GROUP_ID:spot-alert-record-dev}"
    parallelism: ${TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"

notify-storage:
  input:
    topics: "${TRACE_TOPICS:spot-notify-record}"
    group: "${TRACE_GROUP_ID:spot-notify-record-dev}"
    parallelism: ${TRACE_CONSUMERS:3}
    options:
      auto.offset.reset: "${KAFKA_AUTO_OFFSET_RESET:latest}"
      auto.commit.interval.ms: "${KAFKA_AUTO_COMMIT_INTERVAL_MS:1000}"

i18n@metric:

http-server@admin:
  addr: ":7098"
pprof:
prometheus:
